{
 "metadata": {
  "name": "",
  "signature": "sha256:b9e120d4111f51416dd60c9750119cfc55dcf3a6a7f36a14bf77ac480fd242e7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import codecs\n",
      "import collections\n",
      "import itertools\n",
      "import re\n",
      "import unicodedata\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.patches as patches\n",
      "import matplotlib.path as path\n",
      "\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we'll read in the data from the file. We'll use `codecs.open` to convert it to Unicode as we're going. That will allow us to read in and work with the curly quote characters correctly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = codecs.open('Mrs.Dalloway.txt', 'r', 'utf8')\n",
      "raw_text = f.read()\n",
      "print('{} characters read.'.format(len(raw_text)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "359920 characters read.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have the data, let's clean it up some. This will involve several steps:\n",
      "\n",
      "1. Get rid of newlines;\n",
      "1. Case folding."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_text = raw_text.replace('\\n', '').lower()\n",
      "print(clean_text[:75] + '...')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mrs. dalloway said she would buy the flowers herself. for lucy had her work...\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Finding Quotes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can start to identify the quoted quotes. We'll use a regular expression. Let's break it down part-by-part, though, first:\n",
      "\n",
      "* `ur` means that the code should be a `unicode` object, and it shouldn't try to escape any characters. This means that, for instance, \"\\n\" will be interpreted as two characters (backslash and \"n\") not a single newline.\n",
      "* `\u201c` looks for the first open quote.\n",
      "* `[^\u201d]+` matches any character *except* for a close quote. The plus sign means that it needs to find at least one non-close-quote character, but it will match as many as it can find.\n",
      "* `\u201d` finally matches the closing quote.\n",
      "\n",
      "All put together, this regular expression should match the quoted-quotes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "matches = list(re.finditer(ur'\u201c[^\u201d]+\u201d', clean_text))\n",
      "print('{} quoted-quotes found.'.format(len(matches)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "423 quoted-quotes found.\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Locations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see where these quotes are located. We'll essentially create a histogram of the starting locations of all of the matches. We'll process the data into [`numpy`](http://www.numpy.org/) arrays, and we'll use [`matplotlib`](http://matplotlib.org/) to draw the actual graph. (We'll closely follow the [histogram path example](http://matplotlib.org/examples/api/histogram_path_demo.html).\n",
      "\n",
      "For a more finely grained visualization, change the value of the second parameter to `np.histogram`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "locations = [m.start() for m in matches]\n",
      "n, bins = np.histogram(locations, 1000)\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "\n",
      "# corners of the rectangles\n",
      "left = np.array(bins[:-1])\n",
      "right = np.array(bins[1:])\n",
      "bottom = np.zeros(len(left))\n",
      "top = bottom + n\n",
      "\n",
      "XY = np.array([[left, left, right, right], [bottom, top, top, bottom]]).T\n",
      "\n",
      "barpath = path.Path.make_compound_path_from_polys(XY)\n",
      "\n",
      "patch = patches.PathPatch(barpath, facecolor='blue', edgecolor='gray', alpha=0.8)\n",
      "ax.add_patch(patch)\n",
      "\n",
      "ax.set_xlim(left[0], right[-1])\n",
      "ax.set_ylim(bottom.min(), top.max())\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRDz2/wFVtHaK1MgT/AAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10ee90450>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tokenization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have a corpus of the words. Let's break it up into tokens. We'll explicitly keep the punctuation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def take_while(pred, input_str):\n",
      "    \"\"\"This returns the prefix of a string that matches pred,\n",
      "    and the suffix where the match stops.\"\"\"\n",
      "    for (i, c) in enumerate(input_str):\n",
      "        if not pred(c):\n",
      "            return (input_str[:i], input_str[i:])\n",
      "    else:\n",
      "        return (input_str, \"\")\n",
      "\n",
      "def is_punct(c):\n",
      "    \"\"\"Since `unicode` doesn't have a punctuation predicate...\"\"\"\n",
      "    return unicodedata.category(c)[0] == 'P'\n",
      "\n",
      "def tokenize(input_str):\n",
      "    \"\"\"This returns an iterator over the tokens in the string.\"\"\"\n",
      "    rest = None\n",
      "\n",
      "    # Since punctuations are always single characters, this isn't\n",
      "    # handled by `take_while`.\n",
      "    if is_punct(input_str[0]):\n",
      "        yield input_str[0]\n",
      "        rest = input_str[1:]\n",
      "\n",
      "    else:\n",
      "        # Try to match a string of letters or numbers. The first\n",
      "        # that succeeds, yield the token and stop trying.\n",
      "        for p in (unicode.isalpha, unicode.isdigit):\n",
      "            token, rest = take_while(p, input_str)\n",
      "            if token:\n",
      "                yield token\n",
      "                break\n",
      "        # If it wasn't a letter or number, skip a character.\n",
      "        else:\n",
      "            rest = input_str[1:]\n",
      "\n",
      "    # If there's more to try, get its tokenize and yield them.\n",
      "    if rest:\n",
      "        for token in tokenize(rest):\n",
      "            yield token\n",
      "\n",
      "print(list(tokenize(matches[0].group())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'\\u201c', u'musing', u'among', u'the', u'vegetables', u'?', u'\\u201d']\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vector Space Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A common way to deal with NLP documents is as a [vector space model](http://en.wikipedia.org/wiki/Vector_space_model). This takes the words out of order and just stores them as a list of frequencies. It also has to keep a look up table so you can go between words and vector indices easily.\n",
      "\n",
      "To make this easier, let's create a class to handle the lookup tables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class VectorSpace(object):\n",
      "    def __init__(self):\n",
      "        self.by_index = {}\n",
      "        self.by_token = {}\n",
      "    def __len__(self):\n",
      "        return len(self.by_index)\n",
      "    def get_index(self, token):\n",
      "        \"\"\"If it doesn't have an index for the token, create one.\"\"\"\n",
      "        try:\n",
      "            i = self.by_token[token]\n",
      "        except KeyError:\n",
      "            i = len(self.by_token)\n",
      "            self.by_token[token] = i\n",
      "            self.by_index[i] = token\n",
      "        return i\n",
      "    def lookup_token(self, i):\n",
      "        \"\"\"Returns None if there is no token at that position.\"\"\"\n",
      "        return self.by_index.get(i)\n",
      "    def lookup_index(self, token):\n",
      "        \"\"\"Returns None if there is no index for that token.\"\"\"\n",
      "        return self.by_token.get(token)\n",
      "    def vectorize(self, token_seq):\n",
      "        \"\"\"This turns a list of tokens into a numpy array.\"\"\"\n",
      "        v = [0] * len(self.by_token)\n",
      "        for token in token_seq:\n",
      "            i = self.get_index(token)\n",
      "            if i < len(v):\n",
      "                v[i] += 1\n",
      "            elif i == len(v):\n",
      "                v.append(1)\n",
      "            else:\n",
      "                raise Exception(\"Invalid index {} (len = {})\".format(i, len(v)))\n",
      "        return np.array(v)\n",
      "    def pad(self, array):\n",
      "        \"\"\"This pads a numpy array to match the dimensions of this vector space.\"\"\"\n",
      "        padding = np.zeros(len(self) - len(array))\n",
      "        return np.concatenate((array, padding))\n",
      "    \n",
      "vs = VectorSpace()\n",
      "\n",
      "corpus = [list(tokenize(m.group())) for m in matches]\n",
      "vs_corpus = [vs.vectorize(doc) for doc in corpus]\n",
      "vs_corpus = [vs.pad(d) for d in vs_corpus]\n",
      "\n",
      "vs_corpus[0][vs.lookup_index('the')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Frequencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll also want to be able to look at the frequencies of words. We'll filter out the punctuation for this, and then create a `Counter` of the fields."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def frequencies(corpus):\n",
      "    \"\"\"This takes a list of list of tokens and returns a `Counter`.\"\"\"\n",
      "    return collections.Counter(\n",
      "        itertools.ifilter(lambda t: not (len(t) == 1 and is_punct(t)),\n",
      "                          itertools.chain.from_iterable(corpus)))\n",
      "\n",
      "freqs = frequencies(corpus)\n",
      "for (token, freq) in freqs.most_common(25):\n",
      "    print(u'{}\\t{}'.format(token, freq))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the\t78\n",
        "to\t69\n",
        "i\t68\n",
        "you\t65\n",
        "is\t46\n",
        "it\t37\n",
        "s\t36\n",
        "a\t32\n",
        "in\t31\n",
        "my\t30\n",
        "what\t28\n",
        "and\t28\n",
        "have\t26\n",
        "of\t26\n",
        "that\t24\n",
        "are\t24\n",
        "me\t23\n",
        "see\t22\n",
        "how\t20\n",
        "he\t20\n",
        "we\t19\n",
        "but\t19\n",
        "clarissa\t18\n",
        "they\t18\n",
        "come\t17\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}